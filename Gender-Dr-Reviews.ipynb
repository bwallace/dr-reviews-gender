{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "import patsy\n",
    "from patsy import dmatrices\n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.4/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(53401, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.read_csv(\"merged_with_gender.tsv\", delimiter=\"\\t\")\n",
    "# filter out examples where we failed to infer gender\n",
    "genders = ['male', 'female']\n",
    "df_filtered = merged[merged['gender'].isin(genders)]\n",
    "# some cleaning\n",
    "df_filtered[\"knowledge\"] = pd.to_numeric(df_filtered[\"knowledge\"].str.strip(\"&nbsp;\"), errors='coerce')\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df_filtered.groupby('dr-id')\n",
    "ok = list(grouped)[0]\n",
    "np.mean(ok[1][\"helpful\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stolen from stanford people: https://raw.githubusercontent.com/stanfordnlp/CoreNLP/master/data/edu/stanford/nlp/patterns/surface/stopwords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!!', '?!', '??', '!?', '`', '``', \"''\", '-lrb-', '-rrb-', '-lsb-']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = [w.strip() for w in open(\"stopwords.txt\").readlines()]\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove gender pronouns since these aren't terribly interesting as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_pronouns = [\"she\", \"her\", \"hers\", \"his\", \"he\", \"guy\", \"she's\", \"he's\", \"commentshe\", \"commentsshe\", \"man\", \"woman\"]\n",
    "stop_words.extend(gender_pronouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge reviews for individual doctors (we have multiple reviews for each!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_drs = df_filtered[\"dr-id\"].unique()\n",
    "unique_drs.shape\n",
    "grouped = df_filtered.groupby('dr-id')\n",
    "texts, sexes, helpful, knowledge, punctual, ids = [], [], [], [], [], []\n",
    "for i, dr in grouped:\n",
    "    cur_text = \" \".join(dr['review-text'].values)\n",
    "    texts.append(cur_text)\n",
    "    cur_sex = dr[\"gender\"].values[0]\n",
    "    #import pdb; pdb.set_trace()\n",
    "    helpful.append(dr[\"helpful\"].mean(skipna=True)) # assuming missing at random!\n",
    "    knowledge.append(dr[\"knowledge\"].mean(skipna=True)) # assuming missing at random!\n",
    "    ids.append(dr[\"dr-id\"].values[0])\n",
    "    sexes.append(cur_sex)\n",
    "\n",
    "dr_frame = pd.DataFrame({\"sex\":sexes, \"y_helpful\":helpful, \"y_knowledge\":knowledge, \"id\":ids})\n",
    "dr_frame_no_missing = dr_frame.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16485, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_frame_no_missing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many females v males?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2827510917030568"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexes.count(\"female\")/float(len(sexes))\n",
    "#sexes.count(\"female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So about 72% male"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note; should probably pull out and pool reviews for physicians -- here we treat individual reviews for the same physician as multiple / independent instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression analysis for gender-score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important caveats** we are making several assumptions here, including:\n",
    "* We are treating the means as a point estimates and not explicitly weighting by variance\n",
    "* We are ignoring what are likely confounders, including specialties -- e.g., there may be certain specialties that receive lower scores and perhaps women are overrepresented in these. We have no way of knowing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              y_helpful   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     13.99\n",
      "Date:                Fri, 28 Oct 2016   Prob (F-statistic):           0.000185\n",
      "Time:                        12:19:19   Log-Likelihood:                -28355.\n",
      "No. Observations:               16485   AIC:                         5.671e+04\n",
      "Df Residuals:                   16483   BIC:                         5.673e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       3.6467      0.020    184.220      0.000         3.608     3.685\n",
      "sex[T.male]     0.0874      0.023      3.740      0.000         0.042     0.133\n",
      "==============================================================================\n",
      "Omnibus:                     1888.944   Durbin-Watson:                   1.709\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1868.410\n",
      "Skew:                          -0.762   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.372   Cond. No.                         3.53\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y_helpful, X = dmatrices('y_helpful ~ sex', data=dr_frame_no_missing, return_type='dataframe')\n",
    "mod = sm.OLS(y_helpful, X)\n",
    "res_helpful = mod.fit()\n",
    "print(res_helpful.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            y_knowledge   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     17.44\n",
      "Date:                Fri, 28 Oct 2016   Prob (F-statistic):           2.98e-05\n",
      "Time:                        12:19:19   Log-Likelihood:                -27077.\n",
      "No. Observations:               16485   AIC:                         5.416e+04\n",
      "Df Residuals:                   16483   BIC:                         5.417e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       3.8143      0.018    208.224      0.000         3.778     3.850\n",
      "sex[T.male]     0.0903      0.022      4.176      0.000         0.048     0.133\n",
      "==============================================================================\n",
      "Omnibus:                     1862.754   Durbin-Watson:                   1.725\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2572.575\n",
      "Skew:                          -0.966   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.883   Cond. No.                         3.53\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y_knowledge, X = dmatrices('y_knowledge ~ sex', data=dr_frame_no_missing, return_type='dataframe')\n",
    "mod = sm.OLS(y_knowledge, X)\n",
    "res_knowledge = mod.fit()\n",
    "print(res_knowledge.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive analysis; I think Michael's is much better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=20000, min_df=25, ngram_range=(1,1), binary=True, stop_words=stop_words)\n",
    "X = vectorizer.fit_transform(texts)\n",
    "y = sexes\n",
    "param_grid = {\"C\":[.01, .1, 1]}\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid=param_grid, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1, param_grid={'C': [0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54194365591947247"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_most_informative_features(vectorizer, clf, n=50):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print (\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-1.7046\tseemingly      \t\t2.0930\tvague          \n",
      "\t-1.6818\tinpatient      \t\t2.0733\tabruptly       \n",
      "\t-1.5260\tyeast          \t\t1.8747\tcocky          \n",
      "\t-1.4709\treference      \t\t1.7473\tjerk           \n",
      "\t-1.4381\tmary           \t\t1.6032\tpursue         \n",
      "\t-1.4349\tsweetest       \t\t1.5596\treleased       \n",
      "\t-1.4067\tpartum         \t\t1.5320\tprostate       \n",
      "\t-1.3976\teyelid         \t\t1.5188\tbleed          \n",
      "\t-1.3944\tgynecological  \t\t1.5130\tcovering       \n",
      "\t-1.3731\tgown           \t\t1.4894\tsensitivity    \n",
      "\t-1.3725\tultra          \t\t1.4754\tintroduce      \n",
      "\t-1.3722\tjudgmental     \t\t1.4023\tendoscopy      \n",
      "\t-1.3138\tsooo           \t\t1.3919\tnumb           \n",
      "\t-1.3039\tassess         \t\t1.3835\trelative       \n",
      "\t-1.2656\tcommunicative  \t\t1.3684\tdelaware       \n",
      "\t-1.2651\tsounded        \t\t1.3524\tload           \n",
      "\t-1.2547\tsuicide        \t\t1.3518\tplaying        \n",
      "\t-1.2503\tconnected      \t\t1.3170\tneedles        \n",
      "\t-1.2482\tlinda          \t\t1.2973\tmiller         \n",
      "\t-1.2461\t1500           \t\t1.2698\tcanceled       \n",
      "\t-1.2455\targued         \t\t1.2669\tvalley         \n",
      "\t-1.2452\tseizures       \t\t1.2623\tunbearable     \n",
      "\t-1.2437\tcanals         \t\t1.2491\tlecture        \n",
      "\t-1.2412\tchallenged     \t\t1.2446\taccurately     \n",
      "\t-1.2376\tincompetence   \t\t1.2432\tupfront        \n",
      "\t-1.2342\tfaxed          \t\t1.2408\tlawyer         \n",
      "\t-1.2275\tfurthermore    \t\t1.2375\tegotistical    \n",
      "\t-1.2083\tasleep         \t\t1.2361\tfolks          \n",
      "\t-1.2023\tdermatology    \t\t1.2350\tapproached     \n",
      "\t-1.2014\tincorrect      \t\t1.2290\tplanet         \n",
      "\t-1.1993\tfake           \t\t1.2230\tfrightened     \n",
      "\t-1.1934\tgonna          \t\t1.2226\tharder         \n",
      "\t-1.1878\talaska         \t\t1.2014\tdiscs          \n",
      "\t-1.1723\tunknowledgeable\t\t1.1887\tspouse         \n",
      "\t-1.1686\tmeat           \t\t1.1887\tunsympathetic  \n",
      "\t-1.1672\tsuggests       \t\t1.1814\tconsistent     \n",
      "\t-1.1581\tmild           \t\t1.1633\tlicense        \n",
      "\t-1.1426\tcredentials    \t\t1.1631\tretire         \n",
      "\t-1.1408\tcommitment     \t\t1.1626\tdeveloping     \n",
      "\t-1.1397\tparenting      \t\t1.1625\tlap            \n",
      "\t-1.1393\tpushes         \t\t1.1555\tpass           \n",
      "\t-1.1280\tshoulders      \t\t1.1396\tobtained       \n",
      "\t-1.1237\tclock          \t\t1.1256\tarrogant       \n",
      "\t-1.1135\tibs            \t\t1.1235\trich           \n",
      "\t-1.1131\ttolerate       \t\t1.1224\ttylenol        \n",
      "\t-1.1095\tdelayed        \t\t1.1187\tbacked         \n",
      "\t-1.1038\tmelanoma       \t\t1.1134\twrapped        \n",
      "\t-1.1015\tbrings         \t\t1.1102\tcells          \n",
      "\t-1.0834\tstones         \t\t1.1059\tmassive        \n",
      "\t-1.0814\t06             \t\t1.1010\tchiro          \n",
      "\t-1.0805\tsteroid        \t\t1.1004\tjoe            \n",
      "\t-1.0781\tkick           \t\t1.0884\tmastectomy     \n",
      "\t-1.0760\tweak           \t\t1.0872\tpeterson       \n",
      "\t-1.0631\tdanger         \t\t1.0832\tpregnancies    \n",
      "\t-1.0596\tlies           \t\t1.0794\t34             \n",
      "\t-1.0559\tlady           \t\t1.0792\taches          \n",
      "\t-1.0545\tlimit          \t\t1.0769\tpsychiatrists  \n",
      "\t-1.0481\txrays          \t\t1.0764\thero           \n",
      "\t-1.0425\tmotion         \t\t1.0721\tjohn           \n",
      "\t-1.0423\tactions        \t\t1.0682\treviewing      \n",
      "\t-1.0356\trhinoplasty    \t\t1.0623\tdied           \n",
      "\t-1.0305\tmenopause      \t\t1.0555\tfusion         \n",
      "\t-1.0220\tdemonstrated   \t\t1.0501\tuterus         \n",
      "\t-1.0167\tamy            \t\t1.0455\tsubmitted      \n",
      "\t-1.0134\ttech           \t\t1.0441\tfingers        \n",
      "\t-1.0091\tconflict       \t\t1.0432\telbow          \n",
      "\t-1.0082\toverbook       \t\t1.0353\tprecious       \n",
      "\t-1.0025\tdetermined     \t\t1.0349\tscrewed        \n",
      "\t-1.0019\tbirths         \t\t1.0304\tdishonest      \n",
      "\t-0.9803\tdisregarded    \t\t1.0278\tsold           \n",
      "\t-0.9782\tawsome         \t\t1.0277\tnobody         \n",
      "\t-0.9635\tasst           \t\t1.0249\taugust         \n",
      "\t-0.9619\tperforms       \t\t1.0227\tfractured      \n",
      "\t-0.9547\tsocial         \t\t1.0191\tspinal         \n",
      "\t-0.9531\tbadly          \t\t1.0180\tpatel          \n",
      "\t-0.9521\ttremendous     \t\t1.0165\tthankfully     \n",
      "\t-0.9500\tproducts       \t\t1.0150\tfraud          \n",
      "\t-0.9445\tfloor          \t\t1.0138\thandling       \n",
      "\t-0.9438\tlump           \t\t1.0124\tremedies       \n",
      "\t-0.9429\tpreferred      \t\t1.0046\tneurologist    \n",
      "\t-0.9384\tpack           \t\t1.0005\tpulling        \n",
      "\t-0.9380\tnegligent      \t\t0.9976\t2011           \n",
      "\t-0.9363\tkaren          \t\t0.9966\tteaches        \n",
      "\t-0.9343\tred            \t\t0.9923\tincome         \n",
      "\t-0.9319\texaminations   \t\t0.9867\trobert         \n",
      "\t-0.9318\tfinds          \t\t0.9843\tcharleston     \n",
      "\t-0.9250\tparticipate    \t\t0.9789\tbell           \n",
      "\t-0.9243\tconfronted     \t\t0.9767\tjokes          \n",
      "\t-0.9176\tsmear          \t\t0.9766\tcharacter      \n",
      "\t-0.9173\twww            \t\t0.9753\tsolved         \n",
      "\t-0.9049\tdetached       \t\t0.9729\tmarch          \n",
      "\t-0.9026\tmris           \t\t0.9729\tcommented      \n",
      "\t-0.9006\tlaptop         \t\t0.9625\turologist      \n",
      "\t-0.8984\tbipolar        \t\t0.9616\trely           \n",
      "\t-0.8975\tlord           \t\t0.9555\tveins          \n",
      "\t-0.8968\tobnoxious      \t\t0.9513\tdocumentation  \n",
      "\t-0.8963\tbuy            \t\t0.9468\tsuperior       \n",
      "\t-0.8923\tintimidated    \t\t0.9458\tquirky         \n",
      "\t-0.8846\tomaha          \t\t0.9450\tcough          \n",
      "\t-0.8830\tvirginia       \t\t0.9438\tmo             \n"
     ]
    }
   ],
   "source": [
    "show_most_informative_features(vectorizer, clf.best_estimator_, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
