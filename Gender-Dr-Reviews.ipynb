{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53401, 11)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.read_csv(\"merged_with_gender.tsv\", delimiter=\"\\t\")\n",
    "# filter out examples where we failed to infer gender\n",
    "genders = ['male', 'female']\n",
    "df_filtered = merged[merged['gender'].isin(genders)]\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stolen from stanford people: https://raw.githubusercontent.com/stanfordnlp/CoreNLP/master/data/edu/stanford/nlp/patterns/surface/stopwords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!!', '?!', '??', '!?', '`', '``', \"''\", '-lrb-', '-rrb-', '-lsb-']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = [w.strip() for w in open(\"stopwords.txt\").readlines()]\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove gender pronouns since these aren't terribly interesting as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_pronouns = [\"she\", \"her\", \"hers\", \"his\", \"he\", \"guy\", \"she's\", \"he's\", \"commentshe\", \"commentsshe\", \"man\", \"woman\"]\n",
    "stop_words.extend(gender_pronouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge reviews for individual doctors (we have multiple reviews for each!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_drs = df_filtered[\"dr-id\"].unique()\n",
    "unique_drs.shape\n",
    "grouped = df_filtered.groupby('dr-id')\n",
    "texts, sexes = [], []\n",
    "for i, dr in grouped:\n",
    "    cur_text = \" \".join(dr['review-text'].values)\n",
    "    texts.append(cur_text)\n",
    "    cur_sex = dr[\"gender\"].values[0]\n",
    "    sexes.append(cur_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16488"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many females v males?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7172489082969432"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexes.count(\"male\")/float(len(sexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So about 72% male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=20000, min_df=25, ngram_range=(1,1), binary=True, stop_words=stop_words)\n",
    "X = vectorizer.fit_transform(texts)\n",
    "y = sexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note; should probably pull out and pool reviews for physicians -- here we treat individual reviews for the same physician as multiple / independent instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {\"C\":[.01, .1, 1]}\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid=param_grid, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1, param_grid={'C': [0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54194365591947247"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_most_informative_features(vectorizer, clf, n=50):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print (\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-1.7046\tseemingly      \t\t2.0930\tvague          \n",
      "\t-1.6818\tinpatient      \t\t2.0733\tabruptly       \n",
      "\t-1.5260\tyeast          \t\t1.8747\tcocky          \n",
      "\t-1.4709\treference      \t\t1.7473\tjerk           \n",
      "\t-1.4381\tmary           \t\t1.6032\tpursue         \n",
      "\t-1.4349\tsweetest       \t\t1.5596\treleased       \n",
      "\t-1.4067\tpartum         \t\t1.5320\tprostate       \n",
      "\t-1.3976\teyelid         \t\t1.5188\tbleed          \n",
      "\t-1.3944\tgynecological  \t\t1.5130\tcovering       \n",
      "\t-1.3731\tgown           \t\t1.4894\tsensitivity    \n",
      "\t-1.3725\tultra          \t\t1.4754\tintroduce      \n",
      "\t-1.3722\tjudgmental     \t\t1.4023\tendoscopy      \n",
      "\t-1.3138\tsooo           \t\t1.3919\tnumb           \n",
      "\t-1.3039\tassess         \t\t1.3835\trelative       \n",
      "\t-1.2656\tcommunicative  \t\t1.3684\tdelaware       \n",
      "\t-1.2651\tsounded        \t\t1.3524\tload           \n",
      "\t-1.2547\tsuicide        \t\t1.3518\tplaying        \n",
      "\t-1.2503\tconnected      \t\t1.3170\tneedles        \n",
      "\t-1.2482\tlinda          \t\t1.2973\tmiller         \n",
      "\t-1.2461\t1500           \t\t1.2698\tcanceled       \n",
      "\t-1.2455\targued         \t\t1.2669\tvalley         \n",
      "\t-1.2452\tseizures       \t\t1.2623\tunbearable     \n",
      "\t-1.2437\tcanals         \t\t1.2491\tlecture        \n",
      "\t-1.2412\tchallenged     \t\t1.2446\taccurately     \n",
      "\t-1.2376\tincompetence   \t\t1.2432\tupfront        \n",
      "\t-1.2342\tfaxed          \t\t1.2408\tlawyer         \n",
      "\t-1.2275\tfurthermore    \t\t1.2375\tegotistical    \n",
      "\t-1.2083\tasleep         \t\t1.2361\tfolks          \n",
      "\t-1.2023\tdermatology    \t\t1.2350\tapproached     \n",
      "\t-1.2014\tincorrect      \t\t1.2290\tplanet         \n",
      "\t-1.1993\tfake           \t\t1.2230\tfrightened     \n",
      "\t-1.1934\tgonna          \t\t1.2226\tharder         \n",
      "\t-1.1878\talaska         \t\t1.2014\tdiscs          \n",
      "\t-1.1723\tunknowledgeable\t\t1.1887\tspouse         \n",
      "\t-1.1686\tmeat           \t\t1.1887\tunsympathetic  \n",
      "\t-1.1672\tsuggests       \t\t1.1814\tconsistent     \n",
      "\t-1.1581\tmild           \t\t1.1633\tlicense        \n",
      "\t-1.1426\tcredentials    \t\t1.1631\tretire         \n",
      "\t-1.1408\tcommitment     \t\t1.1626\tdeveloping     \n",
      "\t-1.1397\tparenting      \t\t1.1625\tlap            \n",
      "\t-1.1393\tpushes         \t\t1.1555\tpass           \n",
      "\t-1.1280\tshoulders      \t\t1.1396\tobtained       \n",
      "\t-1.1237\tclock          \t\t1.1256\tarrogant       \n",
      "\t-1.1135\tibs            \t\t1.1235\trich           \n",
      "\t-1.1131\ttolerate       \t\t1.1224\ttylenol        \n",
      "\t-1.1095\tdelayed        \t\t1.1187\tbacked         \n",
      "\t-1.1038\tmelanoma       \t\t1.1134\twrapped        \n",
      "\t-1.1015\tbrings         \t\t1.1102\tcells          \n",
      "\t-1.0834\tstones         \t\t1.1059\tmassive        \n",
      "\t-1.0814\t06             \t\t1.1010\tchiro          \n",
      "\t-1.0805\tsteroid        \t\t1.1004\tjoe            \n",
      "\t-1.0781\tkick           \t\t1.0884\tmastectomy     \n",
      "\t-1.0760\tweak           \t\t1.0872\tpeterson       \n",
      "\t-1.0631\tdanger         \t\t1.0832\tpregnancies    \n",
      "\t-1.0596\tlies           \t\t1.0794\t34             \n",
      "\t-1.0559\tlady           \t\t1.0792\taches          \n",
      "\t-1.0545\tlimit          \t\t1.0769\tpsychiatrists  \n",
      "\t-1.0481\txrays          \t\t1.0764\thero           \n",
      "\t-1.0425\tmotion         \t\t1.0721\tjohn           \n",
      "\t-1.0423\tactions        \t\t1.0682\treviewing      \n",
      "\t-1.0356\trhinoplasty    \t\t1.0623\tdied           \n",
      "\t-1.0305\tmenopause      \t\t1.0555\tfusion         \n",
      "\t-1.0220\tdemonstrated   \t\t1.0501\tuterus         \n",
      "\t-1.0167\tamy            \t\t1.0455\tsubmitted      \n",
      "\t-1.0134\ttech           \t\t1.0441\tfingers        \n",
      "\t-1.0091\tconflict       \t\t1.0432\telbow          \n",
      "\t-1.0082\toverbook       \t\t1.0353\tprecious       \n",
      "\t-1.0025\tdetermined     \t\t1.0349\tscrewed        \n",
      "\t-1.0019\tbirths         \t\t1.0304\tdishonest      \n",
      "\t-0.9803\tdisregarded    \t\t1.0278\tsold           \n",
      "\t-0.9782\tawsome         \t\t1.0277\tnobody         \n",
      "\t-0.9635\tasst           \t\t1.0249\taugust         \n",
      "\t-0.9619\tperforms       \t\t1.0227\tfractured      \n",
      "\t-0.9547\tsocial         \t\t1.0191\tspinal         \n",
      "\t-0.9531\tbadly          \t\t1.0180\tpatel          \n",
      "\t-0.9521\ttremendous     \t\t1.0165\tthankfully     \n",
      "\t-0.9500\tproducts       \t\t1.0150\tfraud          \n",
      "\t-0.9445\tfloor          \t\t1.0138\thandling       \n",
      "\t-0.9438\tlump           \t\t1.0124\tremedies       \n",
      "\t-0.9429\tpreferred      \t\t1.0046\tneurologist    \n",
      "\t-0.9384\tpack           \t\t1.0005\tpulling        \n",
      "\t-0.9380\tnegligent      \t\t0.9976\t2011           \n",
      "\t-0.9363\tkaren          \t\t0.9966\tteaches        \n",
      "\t-0.9343\tred            \t\t0.9923\tincome         \n",
      "\t-0.9319\texaminations   \t\t0.9867\trobert         \n",
      "\t-0.9318\tfinds          \t\t0.9843\tcharleston     \n",
      "\t-0.9250\tparticipate    \t\t0.9789\tbell           \n",
      "\t-0.9243\tconfronted     \t\t0.9767\tjokes          \n",
      "\t-0.9176\tsmear          \t\t0.9766\tcharacter      \n",
      "\t-0.9173\twww            \t\t0.9753\tsolved         \n",
      "\t-0.9049\tdetached       \t\t0.9729\tmarch          \n",
      "\t-0.9026\tmris           \t\t0.9729\tcommented      \n",
      "\t-0.9006\tlaptop         \t\t0.9625\turologist      \n",
      "\t-0.8984\tbipolar        \t\t0.9616\trely           \n",
      "\t-0.8975\tlord           \t\t0.9555\tveins          \n",
      "\t-0.8968\tobnoxious      \t\t0.9513\tdocumentation  \n",
      "\t-0.8963\tbuy            \t\t0.9468\tsuperior       \n",
      "\t-0.8923\tintimidated    \t\t0.9458\tquirky         \n",
      "\t-0.8846\tomaha          \t\t0.9450\tcough          \n",
      "\t-0.8830\tvirginia       \t\t0.9438\tmo             \n"
     ]
    }
   ],
   "source": [
    "show_most_informative_features(vectorizer, clf.best_estimator_, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
