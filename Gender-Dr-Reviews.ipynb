{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53401, 11)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.read_csv(\"merged_with_gender.tsv\", delimiter=\"\\t\")\n",
    "# filter out examples where we failed to infer gender\n",
    "genders = ['male', 'female']\n",
    "df_filtered = merged[merged['gender'].isin(genders)]\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stolen from stanford people: https://raw.githubusercontent.com/stanfordnlp/CoreNLP/master/data/edu/stanford/nlp/patterns/surface/stopwords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!!', '?!', '??', '!?', '`', '``', \"''\", '-lrb-', '-rrb-', '-lsb-']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = [w.strip() for w in open(\"stopwords.txt\").readlines()]\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove gender pronouns since these aren't terribly interesting as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_pronouns = [\"she\", \"her\", \"hers\", \"his\", \"he\", \"guy\", \"she's\", \"he's\", \"commentshe\", \"commentsshe\", \"man\", \"woman\"]\n",
    "stop_words.extend(gender_pronouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge reviews for individual doctors (we have multiple reviews for each!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_drs = df_filtered[\"dr-id\"].unique()\n",
    "unique_drs.shape\n",
    "grouped = df_filtered.groupby('dr-id')\n",
    "texts, sexes = [], []\n",
    "for i, dr in grouped:\n",
    "    cur_text = \" \".join(dr['review-text'].values)\n",
    "    texts.append(cur_text)\n",
    "    cur_sex = dr[\"gender\"].values[0]\n",
    "    sexes.append(cur_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16488"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many females v males?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7172489082969432"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexes.count(\"male\")/float(len(sexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So about 72% male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=20000, min_df=5, ngram_range=(1,1), binary=True, stop_words=stop_words)\n",
    "X = vectorizer.fit_transform(texts)\n",
    "y = sexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note; should probably pull out and pool reviews for physicians -- here we treat individual reviews for the same physician as multiple / independent instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {\"C\":[.001, .01, .1]}\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid=param_grid, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.4/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda/lib/python3.4/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda/lib/python3.4/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52564427165110383"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_most_informative_features(vectorizer, clf, n=50):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print (\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-0.7085\tmary           \t\t0.7761\tarrogant       \n",
      "\t-0.6321\tincorrect      \t\t0.7112\tjerk           \n",
      "\t-0.6265\tlady           \t\t0.5469\tneurologist    \n",
      "\t-0.5557\tsweet          \t\t0.5142\tretire         \n",
      "\t-0.5241\tjudgmental     \t\t0.5012\tprostate       \n",
      "\t-0.4774\treference      \t\t0.4733\tlicense        \n",
      "\t-0.4650\tunknowledgeable\t\t0.4572\tvalley         \n",
      "\t-0.4568\tfemale         \t\t0.4444\tupfront        \n",
      "\t-0.4494\tdaiza          \t\t0.4431\tpass           \n",
      "\t-0.4456\ttech           \t\t0.4417\tdied           \n",
      "\t-0.4364\tbarber         \t\t0.4364\tpregnancies    \n",
      "\t-0.4350\texpenses       \t\t0.4364\tjohn           \n",
      "\t-0.4321\tinpatient      \t\t0.4242\tknee           \n",
      "\t-0.4291\tsusan          \t\t0.4197\tnobody         \n",
      "\t-0.4278\tsweetest       \t\t0.4193\tnumb           \n",
      "\t-0.4256\tpushes         \t\t0.4183\taccurately     \n",
      "\t-0.4197\tseemingly      \t\t0.4149\tcocky          \n",
      "\t-0.4181\tmurray         \t\t0.4145\tpossibly       \n",
      "\t-0.4173\tcold           \t\t0.4045\tabruptly       \n",
      "\t-0.4137\targued         \t\t0.4033\tnerve          \n",
      "\t-0.4117\tlump           \t\t0.3997\tintroduce      \n",
      "\t-0.4077\tloved          \t\t0.3983\tvague          \n",
      "\t-0.4074\tfauzia         \t\t0.3980\tsurgery        \n",
      "\t-0.4026\tgyn            \t\t0.3887\tneedles        \n",
      "\t-0.4002\tincompetence   \t\t0.3885\tfusion         \n",
      "\t-0.3970\tweak           \t\t0.3855\thumor          \n",
      "\t-0.3968\tdisorganized   \t\t0.3842\tcanceled       \n",
      "\t-0.3933\txrays          \t\t0.3835\tct             \n",
      "\t-0.3925\tdermatology    \t\t0.3816\tretires        \n",
      "\t-0.3907\tinside         \t\t0.3778\tsensitivity    \n",
      "\t-0.3896\tsoothing       \t\t0.3754\tplaying        \n",
      "\t-0.3871\tfinds          \t\t0.3711\ttowards        \n",
      "\t-0.3791\tgynecological  \t\t0.3697\tchiropractic   \n",
      "\t-0.3781\tpeggy          \t\t0.3694\topposite       \n",
      "\t-0.3779\tlanna          \t\t0.3685\turologist      \n",
      "\t-0.3764\tjahan          \t\t0.3637\treleased       \n",
      "\t-0.3720\tgown           \t\t0.3575\tlaid           \n",
      "\t-0.3709\tinfertility    \t\t0.3567\tedwards        \n",
      "\t-0.3708\tfaxed          \t\t0.3558\tspinal         \n",
      "\t-0.3684\tfake           \t\t0.3556\tdrug           \n",
      "\t-0.3673\tgallo          \t\t0.3529\tsuperior       \n",
      "\t-0.3669\tnewman         \t\t0.3493\thaber          \n",
      "\t-0.3658\tuninformed     \t\t0.3492\tpsychiatrists  \n",
      "\t-0.3644\tcure           \t\t0.3479\tload           \n",
      "\t-0.3591\tcommunicative  \t\t0.3462\tbottom         \n",
      "\t-0.3540\twow            \t\t0.3448\tbleed          \n",
      "\t-0.3531\tyeast          \t\t0.3439\tendoscopy      \n",
      "\t-0.3528\tcompanies      \t\t0.3436\tchecking       \n",
      "\t-0.3518\tproducts       \t\t0.3426\tnose           \n",
      "\t-0.3514\tsooo           \t\t0.3393\trelative       \n",
      "\t-0.3512\tpaper          \t\t0.3391\tcovering       \n",
      "\t-0.3503\tunfriendly     \t\t0.3382\tfibromyalgia   \n",
      "\t-0.3501\tsocial         \t\t0.3379\tincident       \n",
      "\t-0.3500\tyearly         \t\t0.3356\tdelivered      \n",
      "\t-0.3495\t1500           \t\t0.3295\t2011           \n",
      "\t-0.3494\tmean           \t\t0.3287\tfrightened     \n",
      "\t-0.3492\tperforms       \t\t0.3279\texpectations   \n",
      "\t-0.3473\tform           \t\t0.3269\tstarted        \n",
      "\t-0.3464\teclampsia      \t\t0.3248\texplain        \n",
      "\t-0.3462\tmis            \t\t0.3233\torganized      \n",
      "\t-0.3449\twendy          \t\t0.3215\taugmentation   \n",
      "\t-0.3429\tborn           \t\t0.3215\tmark           \n",
      "\t-0.3425\tfuture         \t\t0.3204\tbabies         \n",
      "\t-0.3425\thaven          \t\t0.3200\tcourteous      \n",
      "\t-0.3422\tamy            \t\t0.3182\tuses           \n",
      "\t-0.3417\tstraight       \t\t0.3181\tloves          \n",
      "\t-0.3410\tlies           \t\t0.3174\tfolks          \n",
      "\t-0.3379\tactions        \t\t0.3162\tseriously      \n",
      "\t-0.3357\twaits          \t\t0.3150\tdiabetes       \n",
      "\t-0.3357\tpicco          \t\t0.3147\tuterus         \n",
      "\t-0.3355\tragland        \t\t0.3112\timplant        \n",
      "\t-0.3348\tdoherty        \t\t0.3108\textensive      \n",
      "\t-0.3347\tnp             \t\t0.3100\tcausing        \n",
      "\t-0.3347\tparenting      \t\t0.3089\tinternet       \n",
      "\t-0.3345\tpartum         \t\t0.3078\toperate        \n",
      "\t-0.3340\tsh             \t\t0.3073\tmale           \n",
      "\t-0.3331\tstones         \t\t0.3071\tthankfully     \n",
      "\t-0.3330\tmeat           \t\t0.3062\tpresent        \n",
      "\t-0.3329\tfinally        \t\t0.3044\tapproached     \n",
      "\t-0.3322\tguidelines     \t\t0.3038\toption         \n",
      "\t-0.3317\tratings        \t\t0.3033\tpeter          \n",
      "\t-0.3308\tucla           \t\t0.3031\tspouse         \n",
      "\t-0.3307\trita           \t\t0.3029\tforever        \n",
      "\t-0.3306\tgynecologist   \t\t0.3019\tzager          \n",
      "\t-0.3303\terland         \t\t0.3012\tcells          \n",
      "\t-0.3302\tempathetic     \t\t0.3011\tconversations  \n",
      "\t-0.3281\tremove         \t\t0.3002\tmostly         \n",
      "\t-0.3281\tbadly          \t\t0.3002\tprecious       \n",
      "\t-0.3264\tcommitment     \t\t0.2990\tbrilliant      \n",
      "\t-0.3257\ttremendous     \t\t0.2974\tdavis          \n",
      "\t-0.3257\trx             \t\t0.2972\tthird          \n",
      "\t-0.3252\tcredentials    \t\t0.2969\tsooner         \n",
      "\t-0.3237\tjacob          \t\t0.2964\tjokes          \n",
      "\t-0.3230\tlove           \t\t0.2961\tsolved         \n",
      "\t-0.3229\tassist         \t\t0.2961\taugust         \n",
      "\t-0.3226\texperince      \t\t0.2937\tdelaware       \n",
      "\t-0.3216\tlisted         \t\t0.2935\tmad            \n",
      "\t-0.3214\twhether        \t\t0.2927\tcomprehensive  \n",
      "\t-0.3214\texaminations   \t\t0.2926\tmiller         \n",
      "\t-0.3193\tlinda          \t\t0.2926\tworkers        \n"
     ]
    }
   ],
   "source": [
    "show_most_informative_features(vectorizer, clf.best_estimator_, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
